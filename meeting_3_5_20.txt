3.5.20:
פגישה עם המנחים – 
לעשות גרף שמראה איך אחוז הדיוק יורד ככל שמוחקים יותר מספרים.
זה בסדר שהאימון והולדיציה לא מתבצעים באותו אופן.
לא לעגל את התוצאה של הולידציה – ככה אפשר לראות בכמה לוחות נכשלנו ולמה.
להעריך כמה זמן מבלים על ה-test  - אולי לא לעשות ולידציה כל epoch, או לעשות ולידציה על סט יותר קטן.
שורה 61 – לחלק ב- sum of deleted cells 
שורה 78 – להסתכל על ההדפסה.

לא לקבוע את מספר ה-epchos מראש, אלא להשתמש ב-patience.
לעשות checkpoint ו- restore.
לשמור ביחד עם המודל שאנחנו שומרים את תנאי הריצה.


אפשר לעבוד מרחוק על המעבדה – לדבר עם קובי

שומרים את ה-best model – אם אין התקדמות בולידציה, לטעון את הטוב ששמרנו ואז להמשיך.

לקבע את הלוח – והראות כמה הפרדיקציה משתפרת:
להשוות מול ה-baseline  - כמה אנחנו פחות טובים ממנו.

אם רוצים אקסטרה נקודות:
לעשות embedding של הפיצ'רים האחרונים על ידי TSNE. 
לעשות TSNE (או על ויאליזציה אחרת) על וקטור באורך 729 – ולהשוות בין מה שצדקנו, למה 
שטעינו.

לחשוב על כל מיני ויזואליזציות מעניינות שיעזרו לנו להפיק תובנות.

לתת שם אחר ל-ACC  של ה-train.
לרשום ACC של הולידציה בבת אחת, בנוסף ל-ACC של מחיקה מספר מספר.

ב-CNN ה-learning rate אולי אחר, צריך גם פה לעשות מספר epochs לא מוגבל.

דברים שצריך לעשות:
לעבוד על זה שהאימון יקח פחות זמן – לדבר עם אורלי, פחות ולדיציות.
להבין מה נקודת העצירה שאנחנו רוצים – אולי אפשר כבר לעצור.
לחשוב על ויזואליזציה לאורך הדרך.
לבדוק CNN לעומת FC. הציפייה היא ש- CNN יעבוד טוב יותר מ-FC. 

ברק העלה את ב-ensemble learning – לשים לב שעושים את זה על אותה רשת! לא על רשתות שונות. למשל מאמנים כמה פעמים רשתות FC (או כמה פעמים רשתות CNN) ואז משתמשים באותן רשתות. לעשות את ה-ensemble רק אם זה משפר את התוצאות בלי יותר מדי השקעה.
לשים לב שצריך להתחיל להתכנס למה שעובד, אם יש משהו שיכול לשפר ולוקח יותר מדי זמן אולי לא שווה להשקיע בו.